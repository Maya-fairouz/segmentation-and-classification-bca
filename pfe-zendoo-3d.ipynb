{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11593193,"sourceType":"datasetVersion","datasetId":7269824}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import nibabel as nib\n# import numpy as np\n# import torch\n# from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n# from torchvision import transforms, models\n# import os\n# from sklearn.model_selection import train_test_split\n# import matplotlib.pyplot as plt\n# import pandas as pd\n# import torch.nn as nn\n# import torch.optim as optim\n# from sklearn.metrics import confusion_matrix\n# import seaborn as sns\n# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n\n# # Define paths to your dataset\n# data_dir = \"/kaggle/input/all-zendo-dataset/DATA/\"\n# t2wi_dir = os.path.join(data_dir, \"T2WI\")\n# csv_path = \"/kaggle/input/all-zendo-dataset/DATA/all_centers_combined.csv\"\n\n# # Load the CSV file\n# df = pd.read_csv(csv_path)\n# df['image_name'] = df['image_name'].str.replace('.nii.gz', '.nii')\n# print(\"CSV Columns:\", df.columns)\n# print(\"First few rows of CSV:\")\n# print(df.head())\n\n# # Function to load a NIfTI file\n# def load_nifti(file_path):\n#     nifti = nib.load(file_path)\n#     return nifti.get_fdata()\n\n# # Pair T2WI images with their labels from the CSV\n# image_label_pairs = []\n# for t2wi_subfolder in os.listdir(t2wi_dir):\n#     subfolder_path = os.path.join(t2wi_dir, t2wi_subfolder)\n#     if not os.path.isdir(subfolder_path):\n#         continue\n#     t2wi_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".nii\")]\n#     if t2wi_files:\n#         t2wi_path = os.path.join(subfolder_path, t2wi_files[0])\n#         t2wi_id = t2wi_subfolder.split(\".\")[0]\n#         label_row = df[df['image_name'].str.replace('.nii', '') == t2wi_id]\n#         if not label_row.empty:\n#             label = label_row['label'].iloc[0]\n#             image_label_pairs.append((t2wi_path, label))\n#         else:\n#             print(f\"No label found for T2WI ID {t2wi_id}\")\n\n# print(\"Paired T2WI-Label pairs:\", len(image_label_pairs))\n# for t2wi_path, label in image_label_pairs[:5]:\n#     print(f\"T2WI: {t2wi_path}, Label: {label}\")\n\n# # Compute class weights to handle imbalance\n# labels = [pair[1] for pair in image_label_pairs]\n# nmbic_count = labels.count(0)\n# mbic_count = labels.count(1)\n# total = nmbic_count + mbic_count\n# class_weights = torch.tensor([total / (2 * nmbic_count), total / (2 * mbic_count)]).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n# print(f\"Class Weights (NMBIC, MBIC): {class_weights}\")\n\n# # Define data augmentation and transforms\n# train_transform = A.Compose([\n#     A.Resize(256, 256),\n#     A.HorizontalFlip(p=0.5),\n#     A.VerticalFlip(p=0.5),\n#     A.Rotate(limit=30, p=0.5),\n#     A.RandomBrightnessContrast(p=0.3),\n#     A.Normalize(mean=0.5, std=0.5),\n#     ToTensorV2(),\n# ])\n\n# val_transform = A.Compose([\n#     A.Resize(256, 256),\n#     A.Normalize(mean=0.5, std=0.5),\n#     ToTensorV2(),\n# ])\n\n# # Custom Dataset class for classification\n# class BladderCancerDataset(Dataset):\n#     def __init__(self, image_label_pairs, transform=None):\n#         self.image_label_pairs = image_label_pairs\n#         self.transform = transform\n#         self.slices = []\n#         for idx, (img_path, label) in enumerate(self.image_label_pairs):\n#             try:\n#                 img = load_nifti(img_path)\n#                 img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n#                 middle_slice = img.shape[2] // 2\n#                 self.slices.append((idx, middle_slice, img, label))\n#             except Exception as e:\n#                 print(f\"Error loading {img_path}: {e}\")\n\n#     def __len__(self):\n#         return len(self.slices)\n\n#     def __getitem__(self, idx):\n#         img_idx, z, img, label = self.slices[idx]\n#         img_slice = img[:, :, z]\n#         if self.transform:\n#             augmented = self.transform(image=img_slice)\n#             img_slice = augmented['image']\n#         else:\n#             img_slice = torch.FloatTensor(img_slice).unsqueeze(0)\n#         label = torch.LongTensor([label])\n#         return img_slice, label\n\n#     def get_pair_index(self, idx):\n#         return self.slices[idx][0]\n\n# # Create datasets with transforms\n# train_dataset = BladderCancerDataset(image_label_pairs, transform=train_transform)\n# val_dataset = BladderCancerDataset(image_label_pairs, transform=val_transform)\n\n# # Split at the pair level\n# pair_indices = list(range(len(image_label_pairs)))\n# train_pair_indices, val_pair_indices = train_test_split(pair_indices, test_size=0.2, random_state=42)\n# train_indices, val_indices = [], []\n# for slice_idx in range(len(train_dataset)):\n#     pair_idx = train_dataset.get_pair_index(slice_idx)\n#     if pair_idx in train_pair_indices:\n#         train_indices.append(slice_idx)\n#     elif pair_idx in val_pair_indices:\n#         val_indices.append(slice_idx)\n\n# # Create data loaders\n# train_sampler = SubsetRandomSampler(train_indices)\n# val_sampler = SubsetRandomSampler(val_indices)\n# train_loader = DataLoader(train_dataset, batch_size=8, sampler=train_sampler)\n# val_loader = DataLoader(val_dataset, batch_size=8, sampler=val_sampler)\n\n# # Use a pretrained ResNet50 model\n# model = models.resnet50(pretrained=True)\n# model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n# model.fc = nn.Sequential(\n#     nn.Linear(model.fc.in_features, 512),\n#     nn.ReLU(),\n#     nn.Dropout(0.6),\n#     nn.Linear(512, 2)\n# )\n\n# # Move model to device\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = model.to(device)\n\n# # Define loss, optimizer, and scheduler with weight decay\n# criterion = nn.CrossEntropyLoss(weight=class_weights)\n# optimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-4)\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n\n# # Training loop with validation and early stopping\n# num_epochs = 100\n# train_losses, val_losses = [], []\n# train_accuracies, val_accuracies = [], []\n# best_val_loss = float('inf')\n# patience = 10\n# early_stop_counter = 0\n\n# for epoch in range(num_epochs):\n#     model.train()\n#     train_loss = 0.0\n#     train_correct = 0\n#     train_total = 0\n#     for images_batch, labels_batch in train_loader:\n#         images_batch, labels_batch = images_batch.to(device), labels_batch.to(device).squeeze(1)\n#         outputs = model(images_batch)\n#         loss = criterion(outputs, labels_batch)\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n#         _, predicted = torch.max(outputs, 1)\n#         train_total += labels_batch.size(0)\n#         train_correct += (predicted == labels_batch).sum().item()\n#     train_loss /= len(train_loader)\n#     train_accuracy = train_correct / train_total\n#     train_losses.append(train_loss)\n#     train_accuracies.append(train_accuracy)\n\n#     model.eval()\n#     val_loss = 0.0\n#     val_correct = 0\n#     val_total = 0\n#     all_preds = []\n#     all_labels = []\n#     with torch.no_grad():\n#         for images_batch, labels_batch in val_loader:\n#             images_batch, labels_batch = images_batch.to(device), labels_batch.to(device).squeeze(1)\n#             outputs = model(images_batch)\n#             loss = criterion(outputs, labels_batch)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(outputs, 1)\n#             val_total += labels_batch.size(0)\n#             val_correct += (predicted == labels_batch).sum().item()\n#             all_preds.extend(predicted.cpu().numpy())\n#             all_labels.extend(labels_batch.cpu().numpy())\n#     val_loss /= len(val_loader)\n#     val_accuracy = val_correct / val_total\n#     val_losses.append(val_loss)\n#     val_accuracies.append(val_accuracy)\n\n#     print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n    \n#     scheduler.step(val_loss)\n#     if val_loss < best_val_loss:\n#         best_val_loss = val_loss\n#         early_stop_counter = 0\n#         torch.save(model.state_dict(), \"best_model.pth\")\n#     else:\n#         early_stop_counter += 1\n#         if early_stop_counter >= patience:\n#             print(\"Early stopping triggered!\")\n#             break\n\n# # Load the best model\n# model.load_state_dict(torch.load(\"best_model.pth\"))\n\n# # Plot training and validation accuracy/loss\n# plt.figure(figsize=(12, 5))\n# plt.subplot(1, 2, 1)\n# plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n# plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Val Accuracy')\n# plt.xlabel('Epoch')\n# plt.ylabel('Accuracy')\n# plt.title('Training and Validation Accuracy')\n# plt.legend()\n# plt.grid()\n# plt.subplot(1, 2, 2)\n# plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n# plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.title('Training and Validation Loss')\n# plt.legend()\n# plt.grid()\n# plt.tight_layout()\n# plt.show()\n\n# # Generate and plot confusion matrix\n# cm = confusion_matrix(all_labels, all_preds)\n# plt.figure(figsize=(6, 6))\n# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NMBIC', 'MBIC'], yticklabels=['NMBIC', 'MBIC'])\n# plt.xlabel('Predicted')\n# plt.ylabel('True')\n# plt.title('Confusion Matrix')\n# plt.show()\n\n# # Visualize predictions on validation set\n# model.eval()\n# val_iter = iter(val_loader)\n# images, labels = next(val_iter)\n# images, labels = images.to(device), labels.to(device).squeeze(1)\n# with torch.no_grad():\n#     outputs = model(images)\n#     _, preds = torch.max(outputs, 1)\n# images, labels, preds = images.cpu(), labels.cpu(), preds.cpu()\n# num_samples = min(15, len(images))\n# plt.figure(figsize=(15, 4 * num_samples))\n# for i in range(num_samples):\n#     plt.subplot(num_samples, 2, 2 * i + 1)\n#     plt.imshow(images[i, 0], cmap=\"gray\")\n#     plt.title(f\"Label: {'MBIC' if labels[i] == 1 else 'NMBIC'}\")\n#     plt.axis(\"off\")\n#     plt.subplot(num_samples, 2, 2 * i + 2)\n#     plt.imshow(images[i, 0], cmap=\"gray\")\n#     plt.title(f\"Predicted: {'MBIC' if preds[i] == 1 else 'NMBIC'}\")\n#     plt.axis(\"off\")\n# plt.tight_layout()\n# plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:06:47.101127Z","iopub.execute_input":"2025-05-01T21:06:47.101365Z","iopub.status.idle":"2025-05-01T21:06:47.109674Z","shell.execute_reply.started":"2025-05-01T21:06:47.101347Z","shell.execute_reply":"2025-05-01T21:06:47.108959Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install monai ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:06:47.230989Z","iopub.execute_input":"2025-05-01T21:06:47.231251Z","iopub.status.idle":"2025-05-01T21:07:58.296302Z","shell.execute_reply.started":"2025-05-01T21:06:47.231227Z","shell.execute_reply":"2025-05-01T21:07:58.295603Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed monai-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import nibabel as nib\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom monai.transforms import Compose, Resize, RandFlip, RandRotate, NormalizeIntensity, ToTensor\n\n# Define paths to your dataset\ndata_dir = \"/kaggle/input/all-zendo-dataset/DATA/\"\nt2wi_dir = os.path.join(data_dir, \"T2WI\")\ncsv_path = \"/kaggle/input/all-zendo-dataset/DATA/all_centers_combined.csv\"\n\n# Load the CSV file\ndf = pd.read_csv(csv_path)\ndf['image_name'] = df['image_name'].str.replace('.nii.gz', '.nii')\nprint(\"CSV Columns:\", df.columns)\nprint(\"First few rows of CSV:\")\nprint(df.head())\n\n# Function to load a NIfTI file\ndef load_nifti(file_path):\n    nifti = nib.load(file_path)\n    return nifti.get_fdata()\n\n# Pair T2WI images with their labels from the CSV\nimage_label_pairs = []\nfor t2wi_subfolder in os.listdir(t2wi_dir):\n    subfolder_path = os.path.join(t2wi_dir, t2wi_subfolder)\n    if not os.path.isdir(subfolder_path):\n        continue\n    t2wi_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".nii\")]\n    if t2wi_files:\n        t2wi_path = os.path.join(subfolder_path, t2wi_files[0])\n        t2wi_id = t2wi_subfolder.split(\".\")[0]\n        label_row = df[df['image_name'].str.replace('.nii', '') == t2wi_id]\n        if not label_row.empty:\n            label = label_row['label'].iloc[0]\n            image_label_pairs.append((t2wi_path, label))\n        else:\n            print(f\"No label found for T2WI ID {t2wi_id}\")\n\nprint(\"Paired T2WI-Label pairs:\", len(image_label_pairs))\nfor t2wi_path, label in image_label_pairs[:5]:\n    print(f\"T2WI: {t2wi_path}, Label: {label}\")\n\n# Compute class weights to handle imbalance\nlabels = [pair[1] for pair in image_label_pairs]\nnmbic_count = labels.count(0)\nmbic_count = labels.count(1)\ntotal = nmbic_count + mbic_count\nclass_weights = torch.tensor([total / (2 * nmbic_count), total / (2 * mbic_count)]).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\nprint(f\"Class Weights (NMBIC, MBIC): {class_weights}\")\n\n# Define 3D data augmentation and transforms\ntrain_transform = Compose([\n    Resize(spatial_size=(128, 128, 128)),  # Resize to fixed 3D size\n    RandFlip(prob=0.5, spatial_axis=0),    # Flip along x-axis\n    RandFlip(prob=0.5, spatial_axis=1),    # Flip along y-axis\n    RandRotate(range_x=30, range_y=30, range_z=30, prob=0.5),  # 3D rotation\n    NormalizeIntensity(),                   # Normalize intensity\n    ToTensor()                             # Convert to PyTorch tensor\n])\n\nval_transform = Compose([\n    Resize(spatial_size=(128, 128, 128)),\n    NormalizeIntensity(),\n    ToTensor()\n])\n\n# Custom Dataset class for 3D classification\nclass BladderCancerDataset(Dataset):\n    def __init__(self, image_label_pairs, transform=None):\n        self.image_label_pairs = image_label_pairs\n        self.transform = transform\n        self.volumes = []\n        for idx, (img_path, label) in enumerate(self.image_label_pairs):\n            try:\n                img = load_nifti(img_path)\n                img = (img - img.min()) / (img.max() - img.min() + 1e-8)  # Normalize to [0, 1]\n                self.volumes.append((idx, img, label))\n            except Exception as e:\n                print(f\"Error loading {img_path}: {e}\")\n\n    def __len__(self):\n        return len(self.volumes)\n\n    def __getitem__(self, idx):\n        img_idx, img, label = self.volumes[idx]\n        if self.transform:\n            img = self.transform(img)\n        else:\n            img = torch.FloatTensor(img).unsqueeze(0)  # Add channel dimension: [C, D, H, W]\n        label = torch.LongTensor([label])\n        return img, label\n\n    def get_pair_index(self, idx):\n        return self.volumes[idx][0]\n\n# Create datasets with transforms\ntrain_dataset = BladderCancerDataset(image_label_pairs, transform=train_transform)\nval_dataset = BladderCancerDataset(image_label_pairs, transform=val_transform)\n\n# Split at the pair level\npair_indices = list(range(len(image_label_pairs)))\ntrain_pair_indices, val_pair_indices = train_test_split(pair_indices, test_size=0.2, random_state=42)\ntrain_indices, val_indices = [], []\nfor idx in range(len(train_dataset)):\n    pair_idx = train_dataset.get_pair_index(idx)\n    if pair_idx in train_pair_indices:\n        train_indices.append(idx)\n    elif pair_idx in val_pair_indices:\n        val_indices.append(idx)\n\n# Create data loaders with smaller batch size for 3D\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\ntrain_loader = DataLoader(train_dataset, batch_size=2, sampler=train_sampler)\nval_loader = DataLoader(val_dataset, batch_size=2, sampler=val_sampler)\n\n# Define a simple custom 3D CNN model\nclass Simple3DCNN(nn.Module):\n    def __init__(self):\n        super(Simple3DCNN, self).__init__()\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool3d(2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        # Calculate output size after conv and pooling: 128/2/2/2 = 16\n        self.fc1 = nn.Linear(64 * 16 * 16 * 16, 128)\n        self.fc2 = nn.Linear(128, 2)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.pool(x)\n        x = self.relu(self.conv2(x))\n        x = self.pool(x)\n        x = self.relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Initialize the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Simple3DCNN().to(device)\n\n# Define loss, optimizer, and scheduler with weight decay\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n\n# Training loop with validation and early stopping\nnum_epochs = 100\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\nbest_val_loss = float('inf')\npatience = 10\nearly_stop_counter = 0\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    train_correct = 0\n    train_total = 0\n    for images_batch, labels_batch in train_loader:\n        images_batch, labels_batch = images_batch.to(device), labels_batch.to(device).squeeze(1)\n        outputs = model(images_batch)\n        loss = criterion(outputs, labels_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_total += labels_batch.size(0)\n        train_correct += (predicted == labels_batch).sum().item()\n    train_loss /= len(train_loader)\n    train_accuracy = train_correct / train_total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for images_batch, labels_batch in val_loader:\n            images_batch, labels_batch = images_batch.to(device), labels_batch.to(device).squeeze(1)\n            outputs = model(images_batch)\n            loss = criterion(outputs, labels_batch)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels_batch.size(0)\n            val_correct += (predicted == labels_batch).sum().item()\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels_batch.cpu().numpy())\n    val_loss /= len(val_loader)\n    val_accuracy = val_correct / val_total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n    \n    scheduler.step(val_loss)\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        early_stop_counter = 0\n        torch.save(model.state_dict(), \"best_3d_model.pth\")\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= patience:\n            print(\"Early stopping triggered!\")\n            break\n\n# Load the best model\nmodel.load_state_dict(torch.load(\"best_3d_model.pth\"))\n\n# Plot training and validation accuracy/loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\nplt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.grid()\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.grid()\nplt.tight_layout()\n# plt.savefig('training_validation_plots.png')\n\n# Generate and plot confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NMBIC', 'MBIC'], yticklabels=['NMBIC', 'MBIC'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\n# plt.savefig('confusion_matrix.png')\n\n# Visualize predictions on validation set (show middle slice)\nmodel.eval()\nval_iter = iter(val_loader)\nimages, labels = next(val_iter)\nimages, labels = images.to(device), labels.to(device).squeeze(1)\nwith torch.no_grad():\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\nimages, labels, preds = images.cpu(), labels.cpu(), preds.cpu()\nnum_samples = min(4, len(images))  # Reduced due to memory/display constraints\nplt.figure(figsize=(15, 4 * num_samples))\nfor i in range(num_samples):\n    middle_slice = images[i, 0, images.shape[2] // 2]  # Middle slice along depth\n    plt.subplot(num_samples, 2, 2 * i + 1)\n    plt.imshow(middle_slice, cmap=\"gray\")\n    plt.title(f\"Label: {'MBIC' if labels[i] == 1 else 'NMBIC'}\")\n    plt.axis(\"off\")\n    plt.subplot(num_samples, 2, 2 * i + 2)\n    plt.imshow(middle_slice, cmap=\"gray\")\n    plt.title(f\"Predicted: {'MBIC' if preds[i] == 1 else 'NMBIC'}\")\n    plt.axis(\"off\")\nplt.tight_layout()\n# plt.savefig('prediction_visualization.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:21:30.885172Z","iopub.execute_input":"2025-05-01T21:21:30.885558Z"}},"outputs":[{"name":"stdout","text":"CSV Columns: Index(['label', 'image_name', 'mask_name', 'Age (years)', 'Gender',\n       'Pathological T stage', 'Pathological grade',\n       'Type of patient's tumor number'],\n      dtype='object')\nFirst few rows of CSV:\n   label  image_name      mask_name  Age (years) Gender Pathological T stage  \\\n0      0  c1_001.nii  c1_001.nii.gz           67   Male                   Ta   \n1      0  c1_002.nii  c1_002.nii.gz           58   Male                   Ta   \n2      0  c1_003.nii  c1_003.nii.gz           75   Male                   Ta   \n3      0  c1_004.nii  c1_004.nii.gz           77   Male                   Ta   \n4      1  c1_005.nii  c1_005.nii.gz           67   Male                   T2   \n\n  Pathological grade Type of patient's tumor number  \n0                Low                         Single  \n1                Low                         Single  \n2                Low                         Single  \n3               High                         Single  \n4               High                         Single  \nPaired T2WI-Label pairs: 220\nT2WI: /kaggle/input/all-zendo-dataset/DATA/T2WI/c2_42.nii/XIEDIZUO.nii, Label: 1\nT2WI: /kaggle/input/all-zendo-dataset/DATA/T2WI/c4_29.nii/029 yang wan hui.nii, Label: 1\nT2WI: /kaggle/input/all-zendo-dataset/DATA/T2WI/c1_019.nii/087ZHOUQIAO.nii, Label: 0\nT2WI: /kaggle/input/all-zendo-dataset/DATA/T2WI/c1_111.nii/ZHANG DA QUAN.nii, Label: 0\nT2WI: /kaggle/input/all-zendo-dataset/DATA/T2WI/c1_035.nii/CHENBOREN.nii, Label: 1\nClass Weights (NMBIC, MBIC): tensor([0.7857, 1.3750], device='cuda:0')\n","output_type":"stream"}],"execution_count":null}]}