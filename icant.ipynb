{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nimport nibabel as nib\nfrom scipy import ndimage\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Define paths to your dataset\ndata_dir = \"/kaggle/input/all-zendo-dataset/DATA\"\nt2wi_dir = os.path.join(data_dir, \"T2WI\")\ncsv_path = \"/kaggle/input/all-zendo-dataset/DATA/all_centers_combined.csv\"\n\n# Load the CSV file\ndf = pd.read_csv(csv_path)\ndf['image_name'] = df['image_name'].str.replace('.nii.gz', '.nii')\n\n# Helper functions for preprocessing\ndef read_nifti_file(filepath):\n    scan = nib.load(filepath).get_fdata()\n    return scan\n\ndef normalize(volume):\n    min_hu, max_hu = -1000, 400\n    volume = np.clip(volume, min_hu, max_hu)\n    volume = (volume - min_hu) / (max_hu - min_hu)\n    return volume.astype(\"float32\")\n\ndef resize_volume(img):\n    desired_depth, desired_width, desired_height = 64, 128, 128\n    current_depth, current_width, current_height = img.shape[-1], img.shape[0], img.shape[1]\n    depth_factor = current_depth / desired_depth\n    width_factor = current_width / desired_width\n    height_factor = current_height / desired_height\n    img = ndimage.rotate(img, 90, reshape=False)\n    img = ndimage.zoom(img,\n                       (1/width_factor, 1/height_factor, 1/depth_factor),\n                       order=1)\n    return img\n\ndef process_scan(path):\n    volume = read_nifti_file(path)\n    volume = normalize(volume)\n    return resize_volume(volume)\n\n# Load and pair T2WI images with labels\nnmbic_scan_paths = []\nmbic_scan_paths = []\nfor subfolder in os.listdir(t2wi_dir):\n    folder = os.path.join(t2wi_dir, subfolder)\n    if not os.path.isdir(folder):\n        continue\n    files = [f for f in os.listdir(folder) if f.endswith(\".nii\")]\n    if not files:\n        continue\n    path = os.path.join(folder, files[0])\n    img_id = subfolder.split(\".\")[0]\n    row = df[df['image_name'].str.replace('.nii', '') == img_id]\n    if row.empty:\n        print(f\"No label found for T2WI ID {img_id}\")\n        continue\n    label = int(row['label'].iloc[0])\n    if label == 0:\n        nmbic_scan_paths.append(path)\n    else:\n        mbic_scan_paths.append(path)\n\nprint(f\"NMBIC scans: {len(nmbic_scan_paths)}\")\nprint(f\"MBIC scans: {len(mbic_scan_paths)}\")\n\n# Process scans\nnmbic_scans = np.array([process_scan(p) for p in nmbic_scan_paths])\nmbic_scans = np.array([process_scan(p) for p in mbic_scan_paths])\n\n# Assign labels\nnmbic_labels = np.zeros(len(nmbic_scans), dtype=int)\nmbic_labels = np.ones(len(mbic_scans), dtype=int)\n\n# Split data into training, validation, and test (60-20-20)\ndef split_data(X, y, train_ratio=0.6, val_ratio=0.2):\n    n_total = len(X)\n    n_train = int(train_ratio * n_total)\n    n_val = int(val_ratio * n_total)\n    return X[:n_train], y[:n_train], X[n_train:n_train+n_val], y[n_train:n_train+n_val], X[n_train+n_val:], y[n_train+n_val:]\n\nx_tr_n, y_tr_n, x_val_n, y_val_n, x_test_n, y_test_n = split_data(nmbic_scans, nmbic_labels)\nx_tr_p, y_tr_p, x_val_p, y_val_p, x_test_p, y_test_p = split_data(mbic_scans, mbic_labels)\n\nx_train = np.concatenate((x_tr_p, x_tr_n), axis=0)\ny_train = np.concatenate((y_tr_p, y_tr_n), axis=0)\nx_val = np.concatenate((x_val_p, x_val_n), axis=0)\ny_val = np.concatenate((y_val_p, y_val_n), axis=0)\nx_test = np.concatenate((x_test_p, x_test_n), axis=0)\ny_test = np.concatenate((y_test_p, y_test_n), axis=0)\n\nprint(f\"Number of samples in train, validation, and test are {x_train.shape[0]}, {x_val.shape[0]}, and {x_test.shape[0]}.\")\n\n# Address class imbalance via class weights\nclasses = np.unique(y_train)\ncw = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weight_dict = dict(zip(classes, cw))\nprint(\"Computed class weights:\", class_weight_dict)\n\n# Data augmentation\ndef rotate(volume):\n    def scipy_rotate(vol):\n        angles = [-20, -10, -5, 5, 10, 20]\n        angle = np.random.choice(angles)\n        vol = ndimage.rotate(vol, angle, reshape=False)\n        vol = np.clip(vol, 0, 1)\n        return vol\n    return tf.numpy_function(scipy_rotate, [volume], tf.float32)\n\ndef train_preprocessing(volume, label):\n    volume = rotate(volume)\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\ndef validation_preprocessing(volume, label):\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\n# Define data loaders\nbatch_size = 2\ntrain_dataset = (\n    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n    .shuffle(len(x_train))\n    .map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(2)\n)\nvalidation_dataset = (\n    tf.data.Dataset.from_tensor_slices((x_val, y_val))\n    .map(validation_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(2)\n)\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n    .map(validation_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(2)\n)\n# place of the model \n\n\n# Evaluate on the validation set\nmetrics = model.evaluate(validation_dataset, verbose=0)\nval_loss, val_accuracy, val_precision, val_recall, val_auc = metrics\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\nprint(f\"Validation Precision: {val_precision:.4f}\")\nprint(f\"Validation Recall: {val_recall:.4f}\")\nprint(f\"Validation AUC: {val_auc:.4f}\")\n\n# Evaluate on the test set\nmetrics = model.evaluate(test_dataset, verbose=0)\ntest_loss, test_accuracy, test_precision, test_recall, test_auc = metrics\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {test_precision:.4f}\")\nprint(f\"Test Recall: {test_recall:.4f}\")\nprint(f\"Test AUC: {test_auc:.4f}\")\n\n# Plot training and validation metrics\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n\nplt.subplot(2, 2, 3)\nplt.plot(history.history['recall'], label='Training Recall')\nplt.plot(history.history['val_recall'], label='Validation Recall')\nplt.title('Recall'); plt.xlabel('Epoch'); plt.ylabel('Recall'); plt.legend()\n\nplt.subplot(2, 2, 4)\nplt.plot(history.history['auc'], label='Training AUC')\nplt.plot(history.history['val_auc'], label='Validation AUC')\nplt.title('AUC'); plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.legend()\n\nplt.tight_layout()\nplt.savefig('metrics.png')\nplt.show()\n\n# Collect true labels and predictions for validation set\ny_val_list = np.array([y.numpy() for _, y in validation_dataset.unbatch()]).astype(int)\ny_val_pred = model.predict(validation_dataset)\ny_val_pred_binary = (y_val_pred > 0.5).astype(int)\n\n# DataFrame of validation predictions\nval_df = pd.DataFrame({\n    'Sample Index': np.arange(len(y_val_list)),\n    'True Label': ['MBIC' if l==1 else 'NMBIC' for l in y_val_list],\n    'Pred Label': ['MBIC' if p==1 else 'NMBIC' for p in y_val_pred_binary.flatten()],\n    'Pred Prob': y_val_pred.flatten()\n})\nprint(val_df)\nval_df.to_csv('validation_predictions.csv', index=False)\n\n# Classification report & confusion matrix for validation set\nprint(\"Validation Classification Report:\")\nprint(classification_report(y_val_list, y_val_pred_binary, target_names=[\"NMBIC\",\"MBIC\"]))\ncm = confusion_matrix(y_val_list, y_val_pred_binary)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['NMBIC','MBIC'], yticklabels=['NMBIC','MBIC'])\nplt.title('Validation Confusion Matrix (threshold=0.5)')\nplt.xlabel('Predicted'); plt.ylabel('Actual')\nplt.show()\n\n# Threshold optimization for validation set\nprecisions, recalls, thresholds = precision_recall_curve(y_val_list, y_val_pred)\nopt_thr_f1 = thresholds[np.argmax(2*(precisions*recalls)/(precisions+recalls+1e-8))]\nprint(f\"Validation Optimal threshold (max F1): {opt_thr_f1:.2f}\")\ny_val_pred_opt = (y_val_pred > opt_thr_f1).astype(int)\nprint(\"Validation Classification Report (Optimal Threshold):\")\nprint(classification_report(y_val_list, y_val_pred_opt, target_names=[\"NMBIC\",\"MBIC\"]))\ncm_opt = confusion_matrix(y_val_list, y_val_pred_opt)\nsns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['NMBIC','MBIC'], yticklabels=['NMBIC','MBIC'])\nplt.title(f'Validation Confusion Matrix (threshold={opt_thr_f1:.2f})')\nplt.xlabel('Predicted'); plt.ylabel('Actual')\nplt.show()\n\n# Collect true labels and predictions for test set\ny_test_list = np.array([y.numpy() for _, y in test_dataset.unbatch()]).astype(int)\ny_test_pred = model.predict(test_dataset)\ny_test_pred_binary = (y_test_pred > 0.5).astype(int)\n\n# DataFrame of test predictions\ntest_df = pd.DataFrame({\n    'Sample Index': np.arange(len(y_test_list)),\n    'True Label': ['MBIC' if l==1 else 'NMBIC' for l in y_test_list],\n    'Pred Label': ['MBIC' if p==1 else 'NMBIC' for p in y_test_pred_binary.flatten()],\n    'Pred Prob': y_test_pred.flatten()\n})\nprint(test_df)\ntest_df.to_csv('test_predictions.csv', index=False)\n\n# Classification report & confusion matrix for test set\nprint(\"Test Classification Report:\")\nprint(classification_report(y_test_list, y_test_pred_binary, target_names=[\"NMBIC\",\"MBIC\"]))\ncm = confusion_matrix(y_test_list, y_test_pred_binary)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['NMBIC','MBIC'], yticklabels=['NMBIC','MBIC'])\nplt.title('Test Confusion Matrix (threshold=0.5)')\nplt.xlabel('Predicted'); plt.ylabel('Actual')\nplt.show()\n\n# Threshold optimization for test set\nprecisions, recalls, thresholds = precision_recall_curve(y_test_list, y_test_pred)\nopt_thr_f1 = thresholds[np.argmax(2*(precisions*recalls)/(precisions+recalls+1e-8))]\nprint(f\"Test Optimal threshold (max F1): {opt_thr_f1:.2f}\")\ny_test_pred_opt = (y_test_pred > opt_thr_f1).astype(int)\nprint(\"Test Classification Report (Optimal Threshold):\")\nprint(classification_report(y_test_list, y_test_pred_opt, target_names=[\"NMBIC\",\"MBIC\"]))\ncm_opt = confusion_matrix(y_test_list, y_test_pred_opt)\nsns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['NMBIC','MBIC'], yticklabels=['NMBIC','MBIC'])\nplt.title(f'Test Confusion Matrix (threshold={opt_thr_f1:.2f})')\nplt.xlabel('Predicted'); plt.ylabel('Actual')\nplt.show()\n\n# Save the model\nmodel.save('cnn_bladder_massive.keras')\nprint(\"Model saved as 'cnn_bladder_massive.keras'\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}